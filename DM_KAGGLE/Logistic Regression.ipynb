{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4308fec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "012f51f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 733 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "twitter = pd.read_csv(\"preprocessed_data.csv\")    #normal one used before\n",
    "#twitter = pd.read_csv(\"sorted_preprocessed_data.csv\")  #with lowest emotion scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b07e22de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299</td>\n",
       "      <td>0x2e7caf</td>\n",
       "      <td>my  sunday lineup  girlstrip power  üí™üèæüòé</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>784</td>\n",
       "      <td>0x2eff99</td>\n",
       "      <td>therell never be a  time than now to  what you...</td>\n",
       "      <td>train</td>\n",
       "      <td>trust</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>358</td>\n",
       "      <td>0x3813a3</td>\n",
       "      <td>taluuluu riiiiiiiiiiiiiiiiight üôÑ</td>\n",
       "      <td>train</td>\n",
       "      <td>anger</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1021</td>\n",
       "      <td>0x362eaa</td>\n",
       "      <td>never give up on your dream  me to make your ...</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>367</td>\n",
       "      <td>0x286e23</td>\n",
       "      <td>pearlharper youre the most responsible adult i...</td>\n",
       "      <td>train</td>\n",
       "      <td>surprise</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317658</th>\n",
       "      <td>887</td>\n",
       "      <td>0x27028e</td>\n",
       "      <td>i better go eat something because i havent eat...</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317659</th>\n",
       "      <td>574</td>\n",
       "      <td>0x30ffbb</td>\n",
       "      <td>russia had no bearing on electionpresident did...</td>\n",
       "      <td>train</td>\n",
       "      <td>anger</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317660</th>\n",
       "      <td>91</td>\n",
       "      <td>0x29ccd4</td>\n",
       "      <td>artziiflower beingsalmankhan that meansnow u d...</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317661</th>\n",
       "      <td>532</td>\n",
       "      <td>0x345ac6</td>\n",
       "      <td>talkmaster  now in greenville schigh of  enjoy...</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317662</th>\n",
       "      <td>33</td>\n",
       "      <td>0x3812f6</td>\n",
       "      <td>always going to walk in gods light watch me sh...</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>317663 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        _score  tweet_id                                               text  \\\n",
       "0          299  0x2e7caf            my  sunday lineup  girlstrip power  üí™üèæüòé   \n",
       "1          784  0x2eff99  therell never be a  time than now to  what you...   \n",
       "2          358  0x3813a3                  taluuluu riiiiiiiiiiiiiiiiight üôÑ    \n",
       "3         1021  0x362eaa   never give up on your dream  me to make your ...   \n",
       "4          367  0x286e23  pearlharper youre the most responsible adult i...   \n",
       "...        ...       ...                                                ...   \n",
       "317658     887  0x27028e  i better go eat something because i havent eat...   \n",
       "317659     574  0x30ffbb  russia had no bearing on electionpresident did...   \n",
       "317660      91  0x29ccd4  artziiflower beingsalmankhan that meansnow u d...   \n",
       "317661     532  0x345ac6  talkmaster  now in greenville schigh of  enjoy...   \n",
       "317662      33  0x3812f6  always going to walk in gods light watch me sh...   \n",
       "\n",
       "       identification       emotion  Category  \n",
       "0               train          fear         1  \n",
       "1               train         trust         2  \n",
       "2               train         anger         3  \n",
       "3               train  anticipation         4  \n",
       "4               train      surprise         5  \n",
       "...               ...           ...       ...  \n",
       "317658          train  anticipation         4  \n",
       "317659          train         anger         3  \n",
       "317660          train       sadness         8  \n",
       "317661          train          fear         1  \n",
       "317662          train  anticipation         4  \n",
       "\n",
       "[317663 rows x 6 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6befb911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "#Here we get the TF_IDF for the first 100 features:\n",
    "number_features = 69000\n",
    "\n",
    "tkzr = TweetTokenizer(strip_handles = True)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "                            lowercase=True,\n",
    "                            max_features= number_features,\n",
    "                            #max_df=0.8,\n",
    "                            #min_df=2,\n",
    "                            #ngram_range = (1,3),\n",
    "                            #stop_words = \"english\",\n",
    "                            tokenizer = tkzr.tokenize\n",
    "                            )\n",
    "\n",
    "vectors = tfidf_vectorizer.fit_transform(twitter['text'])\n",
    "\n",
    "feature_names = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "502c7bfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 63 epochs took 16 seconds\n",
      "Accuracy Score: 0.4453118851620418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   15.9s finished\n"
     ]
    }
   ],
   "source": [
    "# validate: split into train and test\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectors, twitter['emotion'], test_size=0.2, random_state=42)\n",
    "\n",
    "# model\n",
    "lr = LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, max_iter=1000,\n",
    "                   multi_class='multinomial', n_jobs=-1, penalty='l2',\n",
    "                   random_state=None, solver='saga', tol=0.0001, verbose=2,\n",
    "                   warm_start=False)\n",
    "\n",
    "#the ones that first worked were -> solver: liblinear  ;  multi_class: auto\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "371a46e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_test_data = pd.read_csv(\"twitter_test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0a1529bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_twitter = tfidf_vectorizer.transform(twitter_test_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "01c202a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_predict = lr.predict(x_test_twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "aad07344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x218443</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x26289a</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411967</th>\n",
       "      <td>0x2913b4</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411968</th>\n",
       "      <td>0x2a980e</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411969</th>\n",
       "      <td>0x316b80</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411970</th>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411971</th>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id       emotion\n",
       "0       0x28b412  anticipation\n",
       "1       0x2de201  anticipation\n",
       "2       0x218443           joy\n",
       "3       0x2939d5           joy\n",
       "4       0x26289a          fear\n",
       "...          ...           ...\n",
       "411967  0x2913b4  anticipation\n",
       "411968  0x2a980e  anticipation\n",
       "411969  0x316b80         anger\n",
       "411970  0x29d0cb           joy\n",
       "411971  0x2a6a4f         anger\n",
       "\n",
       "[411972 rows x 2 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_df = pd.DataFrame(columns = [[\"id\",\"emotion\"]])\n",
    "upload_df[\"id\"] = twitter_test_data[\"tweet_id\"]\n",
    "upload_df[\"emotion\"] = new_predict\n",
    "upload_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "217aa9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_df.to_csv(\"./uploads/logistic_try_1.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
