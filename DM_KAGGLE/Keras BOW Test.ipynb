{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 546 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "twitter = pd.read_csv(\"preprocessed_data.csv\")    #normal one used before\n",
    "#twitter = pd.read_csv(\"sorted_preprocessed_data.csv\")  #with lowest emotion scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299</td>\n",
       "      <td>0x2e7caf</td>\n",
       "      <td>my  sunday lineup  girlstrip power  üí™üèæüòé</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>784</td>\n",
       "      <td>0x2eff99</td>\n",
       "      <td>therell never be a  time than now to  what you...</td>\n",
       "      <td>train</td>\n",
       "      <td>trust</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>358</td>\n",
       "      <td>0x3813a3</td>\n",
       "      <td>taluuluu riiiiiiiiiiiiiiiiight üôÑ</td>\n",
       "      <td>train</td>\n",
       "      <td>anger</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1021</td>\n",
       "      <td>0x362eaa</td>\n",
       "      <td>never give up on your dream  me to make your ...</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>367</td>\n",
       "      <td>0x286e23</td>\n",
       "      <td>pearlharper youre the most responsible adult i...</td>\n",
       "      <td>train</td>\n",
       "      <td>surprise</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317658</th>\n",
       "      <td>887</td>\n",
       "      <td>0x27028e</td>\n",
       "      <td>i better go eat something because i havent eat...</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317659</th>\n",
       "      <td>574</td>\n",
       "      <td>0x30ffbb</td>\n",
       "      <td>russia had no bearing on electionpresident did...</td>\n",
       "      <td>train</td>\n",
       "      <td>anger</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317660</th>\n",
       "      <td>91</td>\n",
       "      <td>0x29ccd4</td>\n",
       "      <td>artziiflower beingsalmankhan that meansnow u d...</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317661</th>\n",
       "      <td>532</td>\n",
       "      <td>0x345ac6</td>\n",
       "      <td>talkmaster  now in greenville schigh of  enjoy...</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317662</th>\n",
       "      <td>33</td>\n",
       "      <td>0x3812f6</td>\n",
       "      <td>always going to walk in gods light watch me sh...</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>317663 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        _score  tweet_id                                               text  \\\n",
       "0          299  0x2e7caf            my  sunday lineup  girlstrip power  üí™üèæüòé   \n",
       "1          784  0x2eff99  therell never be a  time than now to  what you...   \n",
       "2          358  0x3813a3                  taluuluu riiiiiiiiiiiiiiiiight üôÑ    \n",
       "3         1021  0x362eaa   never give up on your dream  me to make your ...   \n",
       "4          367  0x286e23  pearlharper youre the most responsible adult i...   \n",
       "...        ...       ...                                                ...   \n",
       "317658     887  0x27028e  i better go eat something because i havent eat...   \n",
       "317659     574  0x30ffbb  russia had no bearing on electionpresident did...   \n",
       "317660      91  0x29ccd4  artziiflower beingsalmankhan that meansnow u d...   \n",
       "317661     532  0x345ac6  talkmaster  now in greenville schigh of  enjoy...   \n",
       "317662      33  0x3812f6  always going to walk in gods light watch me sh...   \n",
       "\n",
       "       identification       emotion  Category  \n",
       "0               train          fear         1  \n",
       "1               train         trust         2  \n",
       "2               train         anger         3  \n",
       "3               train  anticipation         4  \n",
       "4               train      surprise         5  \n",
       "...               ...           ...       ...  \n",
       "317658          train  anticipation         4  \n",
       "317659          train         anger         3  \n",
       "317660          train       sadness         8  \n",
       "317661          train          fear         1  \n",
       "317662          train  anticipation         4  \n",
       "\n",
       "[317663 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 1000)\n",
    "twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing the dataframe into a train and a test sections\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(twitter.text,twitter.emotion,\n",
    "                                                test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:489: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(max_features=5000,\n",
       "                tokenizer=<function word_tokenize at 0x0000021528110310>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "BOW = CountVectorizer(tokenizer=nltk.word_tokenize, max_features=35000) #max_features=500\n",
    "\n",
    "BOW.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = BOW.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"üòï\" in feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255439    have you ever thought about the fact that it‚Äôs...\n",
       "59813     doomseee doomseee you misspelled doomsee unles...\n",
       "101110    cultural appropriation one word yoga culturala...\n",
       "212739    jancello carnegiehall  billmurray hero kinda g...\n",
       "43393                         musta been a sale on denim üòÇ \n",
       "                                ...                        \n",
       "119879        even the halftime performance lacked offense \n",
       "259178    closed sell  lots eurusd  for  pips total for ...\n",
       "131932    the patriots are no better than the jets right...\n",
       "146867                 just so much bored  frustrated and  \n",
       "121958    inthenameofindia congress decides to play divi...\n",
       "Name: text, Length: 254130, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape:  (254130, 5000)\n",
      "y_train.shape:  (254130,)\n",
      "x_test.shape:  (63533, 5000)\n",
      "y_test.shape:  (63533,)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "x_train = BOW.transform(x_train)\n",
    "#y_train = y_train\n",
    "\n",
    "x_test = BOW.transform(x_test)\n",
    "#y_test = y_test\n",
    "\n",
    "print('x_train.shape: ', x_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('x_test.shape: ', x_test.shape)\n",
    "print('y_test.shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33625            anger\n",
       "32213              joy\n",
       "71328         surprise\n",
       "10175            trust\n",
       "156317           trust\n",
       "              ...     \n",
       "225865         disgust\n",
       "260173         disgust\n",
       "230576    anticipation\n",
       "222294        surprise\n",
       "83967            trust\n",
       "Name: emotion, Length: 63533, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255439    surprise\n",
       "59813      sadness\n",
       "101110     disgust\n",
       "212739       trust\n",
       "43393         fear\n",
       "            ...   \n",
       "119879        fear\n",
       "259178         joy\n",
       "131932     disgust\n",
       "146867       anger\n",
       "121958     disgust\n",
       "Name: emotion, Length: 254130, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check label:  ['anger' 'anticipation' 'disgust' 'fear' 'joy' 'sadness' 'surprise'\n",
      " 'trust']\n",
      "\n",
      "## Before convert\n",
      "y_train[0:4]:\n",
      " 255439    surprise\n",
      "59813      sadness\n",
      "101110     disgust\n",
      "212739       trust\n",
      "Name: emotion, dtype: object\n",
      "\n",
      "y_train.shape:  (254130,)\n",
      "y_test.shape:  (63533,)\n",
      "\n",
      "\n",
      "## After convert\n",
      "y_train[0:4]:\n",
      " [[0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "\n",
      "y_train.shape:  (254130, 8)\n",
      "y_test.shape:  (63533, 8)\n"
     ]
    }
   ],
   "source": [
    "## deal with label (string -> one-hot)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "print('check label: ', label_encoder.classes_)\n",
    "print('\\n## Before convert')\n",
    "print('y_train[0:4]:\\n', y_train[0:4])\n",
    "print('\\ny_train.shape: ', y_train.shape)\n",
    "print('y_test.shape: ', y_test.shape)\n",
    "\n",
    "def label_encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    #return keras.utils.to_categorical(enc)\n",
    "    return keras.utils.np_utils.to_categorical(enc)   #Allison/Moo said so, because of version\n",
    "\n",
    "def label_decode(le, one_hot_label):\n",
    "    dec = np.argmax(one_hot_label, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "y_train = label_encode(label_encoder, y_train)\n",
    "y_test = label_encode(label_encoder, y_test)\n",
    "\n",
    "print('\\n\\n## After convert')\n",
    "print('y_train[0:4]:\\n', y_train[0:4])\n",
    "print('\\ny_train.shape: ', y_train.shape)\n",
    "print('y_test.shape: ', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape:  5000\n",
      "output_shape:  8\n"
     ]
    }
   ],
   "source": [
    "# I/O check\n",
    "input_shape = x_train.shape[1]\n",
    "print('input_shape: ', input_shape)\n",
    "\n",
    "output_shape = len(label_encoder.classes_)\n",
    "print('output_shape: ', output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 5000)]            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                320064    \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      " softmax (Softmax)           (None, 8)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,744\n",
      "Trainable params: 324,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import ReLU, Softmax\n",
    "\n",
    "# input layer\n",
    "model_input = Input(shape=(input_shape, ))  # 10000\n",
    "X = model_input\n",
    "\n",
    "# 1st hidden layer\n",
    "X_W1 = Dense(units=64)(X)  # 64,32\n",
    "H1 = ReLU()(X_W1)\n",
    "\n",
    "# 2nd hidden layer\n",
    "H1_W2 = Dense(units=64)(H1)  # 64,32\n",
    "H2 = ReLU()(H1_W2)\n",
    "\n",
    "# output layer\n",
    "H2_W3 = Dense(units=output_shape)(H2)  # 4\n",
    "H3 = Softmax()(H2_W3)\n",
    "\n",
    "model_output = H3\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=[model_input], outputs=[model_output])\n",
    "\n",
    "# loss function & optimizer\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# show model construction\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/dense/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/dense/embedding_lookup_sparse/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/dense/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3971/3971 [==============================] - 8s 2ms/step - loss: 1.6065 - accuracy: 0.4082 - val_loss: 1.5472 - val_accuracy: 0.4323\n",
      "Epoch 2/25\n",
      "3971/3971 [==============================] - 8s 2ms/step - loss: 1.4719 - accuracy: 0.4626 - val_loss: 1.5462 - val_accuracy: 0.4338\n",
      "Epoch 3/25\n",
      "3971/3971 [==============================] - 8s 2ms/step - loss: 1.3927 - accuracy: 0.4946 - val_loss: 1.5623 - val_accuracy: 0.4291\n",
      "Epoch 4/25\n",
      "3971/3971 [==============================] - 8s 2ms/step - loss: 1.3176 - accuracy: 0.5256 - val_loss: 1.6047 - val_accuracy: 0.4234\n",
      "Epoch 5/25\n",
      "3971/3971 [==============================] - 8s 2ms/step - loss: 1.2470 - accuracy: 0.5535 - val_loss: 1.6547 - val_accuracy: 0.4211\n",
      "Epoch 6/25\n",
      "3971/3971 [==============================] - 8s 2ms/step - loss: 1.1835 - accuracy: 0.5778 - val_loss: 1.7112 - val_accuracy: 0.4165\n",
      "Epoch 7/25\n",
      "3971/3971 [==============================] - 8s 2ms/step - loss: 1.1265 - accuracy: 0.6001 - val_loss: 1.7761 - val_accuracy: 0.4103\n",
      "Epoch 8/25\n",
      "3971/3971 [==============================] - 8s 2ms/step - loss: 1.0747 - accuracy: 0.6214 - val_loss: 1.8624 - val_accuracy: 0.4058\n",
      "Epoch 9/25\n",
      "3971/3971 [==============================] - 8s 2ms/step - loss: 1.0285 - accuracy: 0.6378 - val_loss: 1.9262 - val_accuracy: 0.4021\n",
      "Epoch 10/25\n",
      "3971/3971 [==============================] - 8s 2ms/step - loss: 0.9871 - accuracy: 0.6533 - val_loss: 2.0206 - val_accuracy: 0.4001\n",
      "Epoch 11/25\n",
      "3971/3971 [==============================] - 8s 2ms/step - loss: 0.9498 - accuracy: 0.6666 - val_loss: 2.1010 - val_accuracy: 0.3973\n",
      "Epoch 12/25\n",
      "3971/3971 [==============================] - 8s 2ms/step - loss: 0.9141 - accuracy: 0.6797 - val_loss: 2.2009 - val_accuracy: 0.3943\n",
      "Epoch 13/25\n",
      "3971/3971 [==============================] - 8s 2ms/step - loss: 0.8839 - accuracy: 0.6908 - val_loss: 2.3136 - val_accuracy: 0.3914\n",
      "Epoch 14/25\n",
      "3971/3971 [==============================] - 8s 2ms/step - loss: 0.8546 - accuracy: 0.7016 - val_loss: 2.4024 - val_accuracy: 0.3891\n",
      "Epoch 15/25\n",
      "3971/3971 [==============================] - 8s 2ms/step - loss: 0.8289 - accuracy: 0.7101 - val_loss: 2.5024 - val_accuracy: 0.3889\n",
      "Epoch 16/25\n",
      "3971/3971 [==============================] - 8s 2ms/step - loss: 0.8043 - accuracy: 0.7193 - val_loss: 2.6139 - val_accuracy: 0.3866\n",
      "Epoch 17/25\n",
      "3971/3971 [==============================] - 8s 2ms/step - loss: 0.7814 - accuracy: 0.7274 - val_loss: 2.7335 - val_accuracy: 0.3847\n",
      "Epoch 18/25\n",
      "3971/3971 [==============================] - 8s 2ms/step - loss: 0.7609 - accuracy: 0.7357 - val_loss: 2.8393 - val_accuracy: 0.3847\n",
      "Epoch 19/25\n",
      "3971/3971 [==============================] - 8s 2ms/step - loss: 0.7415 - accuracy: 0.7416 - val_loss: 2.9217 - val_accuracy: 0.3808\n",
      "Epoch 20/25\n",
      "3971/3971 [==============================] - 8s 2ms/step - loss: 0.7231 - accuracy: 0.7491 - val_loss: 3.0213 - val_accuracy: 0.3822\n",
      "Epoch 21/25\n",
      "3971/3971 [==============================] - 8s 2ms/step - loss: 0.7061 - accuracy: 0.7539 - val_loss: 3.1818 - val_accuracy: 0.3799\n",
      "Epoch 22/25\n",
      "3971/3971 [==============================] - 8s 2ms/step - loss: 0.6906 - accuracy: 0.7594 - val_loss: 3.3172 - val_accuracy: 0.3796\n",
      "Epoch 23/25\n",
      "3971/3971 [==============================] - 8s 2ms/step - loss: 0.6755 - accuracy: 0.7653 - val_loss: 3.3982 - val_accuracy: 0.3789\n",
      "Epoch 24/25\n",
      "3971/3971 [==============================] - 8s 2ms/step - loss: 0.6611 - accuracy: 0.7697 - val_loss: 3.4795 - val_accuracy: 0.3775\n",
      "Epoch 25/25\n",
      "3971/3971 [==============================] - 8s 2ms/step - loss: 0.6485 - accuracy: 0.7746 - val_loss: 3.6558 - val_accuracy: 0.3782\n",
      "training finish\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "csv_logger = CSVLogger('logs/training_log.csv')\n",
    "\n",
    "# training setting\n",
    "epochs = 25\n",
    "batch_size = 64\n",
    "\n",
    "# training!\n",
    "history = model.fit(x_train, y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=batch_size, \n",
    "                    callbacks=[csv_logger],\n",
    "                    validation_data = (x_test, y_test))\n",
    "print('training finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.3125936e-02, 8.4794708e-02, 1.6015072e-01, 2.0436341e-01,\n",
       "        1.8838915e-01, 2.2306383e-01, 1.3508905e-02, 5.2603323e-02],\n",
       "       [2.5909230e-02, 2.4049428e-01, 4.8615481e-03, 1.5954448e-01,\n",
       "        2.5047976e-01, 8.1039332e-02, 6.4712211e-02, 1.7295921e-01],\n",
       "       [4.1640028e-01, 2.7003378e-01, 5.4407746e-02, 1.4857202e-03,\n",
       "        7.2487915e-04, 6.4973631e-03, 2.4792923e-01, 2.5209750e-03],\n",
       "       [5.1111871e-01, 1.8782986e-02, 7.4551383e-05, 2.0236896e-01,\n",
       "        9.5500881e-03, 6.3989472e-05, 5.4908602e-04, 2.5749168e-01],\n",
       "       [5.0795225e-06, 4.1107032e-02, 2.4736724e-05, 1.1050173e-04,\n",
       "        4.0103678e-05, 9.2584064e-04, 3.5749935e-02, 9.2203683e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predict\n",
    "pred_result = model.predict(x_test, batch_size=128) #128\n",
    "pred_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sadness', 'joy', 'anger', 'anger', 'trust'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result = label_decode(label_encoder, pred_result)\n",
    "pred_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy: 0.38\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('testing accuracy: {}'.format(round(accuracy_score(label_decode(label_encoder, y_test), pred_result), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>1.606529</td>\n",
       "      <td>0.432326</td>\n",
       "      <td>1.547189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.462649</td>\n",
       "      <td>1.471947</td>\n",
       "      <td>0.433838</td>\n",
       "      <td>1.546177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.494641</td>\n",
       "      <td>1.392706</td>\n",
       "      <td>0.429147</td>\n",
       "      <td>1.562348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.525609</td>\n",
       "      <td>1.317649</td>\n",
       "      <td>0.423433</td>\n",
       "      <td>1.604676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.553488</td>\n",
       "      <td>1.247015</td>\n",
       "      <td>0.421135</td>\n",
       "      <td>1.654745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.577846</td>\n",
       "      <td>1.183496</td>\n",
       "      <td>0.416539</td>\n",
       "      <td>1.711175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.600091</td>\n",
       "      <td>1.126486</td>\n",
       "      <td>0.410259</td>\n",
       "      <td>1.776064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.621371</td>\n",
       "      <td>1.074741</td>\n",
       "      <td>0.405789</td>\n",
       "      <td>1.862427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.637764</td>\n",
       "      <td>1.028536</td>\n",
       "      <td>0.402122</td>\n",
       "      <td>1.926172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.653268</td>\n",
       "      <td>0.987071</td>\n",
       "      <td>0.400138</td>\n",
       "      <td>2.020573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.666588</td>\n",
       "      <td>0.949792</td>\n",
       "      <td>0.397321</td>\n",
       "      <td>2.100964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.679660</td>\n",
       "      <td>0.914065</td>\n",
       "      <td>0.394331</td>\n",
       "      <td>2.200853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.690835</td>\n",
       "      <td>0.883932</td>\n",
       "      <td>0.391403</td>\n",
       "      <td>2.313597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.701550</td>\n",
       "      <td>0.854553</td>\n",
       "      <td>0.389073</td>\n",
       "      <td>2.402432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.710148</td>\n",
       "      <td>0.828873</td>\n",
       "      <td>0.388853</td>\n",
       "      <td>2.502433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.719281</td>\n",
       "      <td>0.804330</td>\n",
       "      <td>0.386649</td>\n",
       "      <td>2.613903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.727435</td>\n",
       "      <td>0.781440</td>\n",
       "      <td>0.384666</td>\n",
       "      <td>2.733496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.735730</td>\n",
       "      <td>0.760916</td>\n",
       "      <td>0.384745</td>\n",
       "      <td>2.839311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.741577</td>\n",
       "      <td>0.741481</td>\n",
       "      <td>0.380778</td>\n",
       "      <td>2.921741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.749062</td>\n",
       "      <td>0.723123</td>\n",
       "      <td>0.382164</td>\n",
       "      <td>3.021317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.753945</td>\n",
       "      <td>0.706067</td>\n",
       "      <td>0.379944</td>\n",
       "      <td>3.181843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.759367</td>\n",
       "      <td>0.690604</td>\n",
       "      <td>0.379598</td>\n",
       "      <td>3.317217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.765266</td>\n",
       "      <td>0.675493</td>\n",
       "      <td>0.378874</td>\n",
       "      <td>3.398168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.769720</td>\n",
       "      <td>0.661091</td>\n",
       "      <td>0.377473</td>\n",
       "      <td>3.479543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.774564</td>\n",
       "      <td>0.648466</td>\n",
       "      <td>0.378244</td>\n",
       "      <td>3.655823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  accuracy      loss  val_accuracy  val_loss\n",
       "0       0  0.408248  1.606529      0.432326  1.547189\n",
       "1       1  0.462649  1.471947      0.433838  1.546177\n",
       "2       2  0.494641  1.392706      0.429147  1.562348\n",
       "3       3  0.525609  1.317649      0.423433  1.604676\n",
       "4       4  0.553488  1.247015      0.421135  1.654745\n",
       "5       5  0.577846  1.183496      0.416539  1.711175\n",
       "6       6  0.600091  1.126486      0.410259  1.776064\n",
       "7       7  0.621371  1.074741      0.405789  1.862427\n",
       "8       8  0.637764  1.028536      0.402122  1.926172\n",
       "9       9  0.653268  0.987071      0.400138  2.020573\n",
       "10     10  0.666588  0.949792      0.397321  2.100964\n",
       "11     11  0.679660  0.914065      0.394331  2.200853\n",
       "12     12  0.690835  0.883932      0.391403  2.313597\n",
       "13     13  0.701550  0.854553      0.389073  2.402432\n",
       "14     14  0.710148  0.828873      0.388853  2.502433\n",
       "15     15  0.719281  0.804330      0.386649  2.613903\n",
       "16     16  0.727435  0.781440      0.384666  2.733496\n",
       "17     17  0.735730  0.760916      0.384745  2.839311\n",
       "18     18  0.741577  0.741481      0.380778  2.921741\n",
       "19     19  0.749062  0.723123      0.382164  3.021317\n",
       "20     20  0.753945  0.706067      0.379944  3.181843\n",
       "21     21  0.759367  0.690604      0.379598  3.317217\n",
       "22     22  0.765266  0.675493      0.378874  3.398168\n",
       "23     23  0.769720  0.661091      0.377473  3.479543\n",
       "24     24  0.774564  0.648466      0.378244  3.655823"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's take a look at the training log\n",
    "training_log = pd.DataFrame()\n",
    "training_log = pd.read_csv(\"logs/training_log.csv\")\n",
    "training_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_test_data = pd.read_csv(\"twitter_test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test.shape:  (411972, 5000)\n"
     ]
    }
   ],
   "source": [
    "x_test_twitter = BOW.transform(twitter_test_data['text'])\n",
    "\n",
    "pred_result_test_data = model.predict(x_test_twitter, batch_size=128)\n",
    "\n",
    "print('x_test.shape: ', x_test_twitter.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411972"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_result_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['trust', 'anticipation', 'anticipation', 'joy', 'anticipation'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result_test_data = label_decode(label_encoder, pred_result_test_data)\n",
    "pred_result_test_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x218443</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x26289a</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411967</th>\n",
       "      <td>0x2913b4</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411968</th>\n",
       "      <td>0x2a980e</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411969</th>\n",
       "      <td>0x316b80</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411970</th>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411971</th>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id       emotion\n",
       "0       0x28b412         trust\n",
       "1       0x2de201  anticipation\n",
       "2       0x218443  anticipation\n",
       "3       0x2939d5           joy\n",
       "4       0x26289a  anticipation\n",
       "...          ...           ...\n",
       "411967  0x2913b4  anticipation\n",
       "411968  0x2a980e           joy\n",
       "411969  0x316b80  anticipation\n",
       "411970  0x29d0cb         anger\n",
       "411971  0x2a6a4f       sadness\n",
       "\n",
       "[411972 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_df = pd.DataFrame()\n",
    "upload_df[\"id\"] = twitter_test_data[\"tweet_id\"]\n",
    "upload_df[\"emotion\"] = pred_result_test_data\n",
    "upload_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_df.emotion.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_df.to_csv(\"predictions/BOWKeras.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look for stemmer: going -> go "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
